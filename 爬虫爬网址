import requests
from bs4 import BeautifulSoup

def simple_web_crawler(url):
    # 发送 HTTP 请求
    response = requests.get(url)

    # 检查请求是否成功
    if response.status_code == 200:
        # 解析 HTML 内容
        soup = BeautifulSoup(response.text, 'html.parser')

        # 查找所有的链接
        links = soup.find_all('a')

        # 提取并打印链接
        for link in links:
            href = link.get('href')
            if href:
                print(href)
    else:
        print(f"Failed to retrieve the webpage. Status code: {response.status_code}")

# 使用示例
simple_web_crawler('https://www.4399.com')
